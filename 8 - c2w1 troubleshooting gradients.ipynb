{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def gradient_check_n(parameters, gradients, X, Y, epsilon = 1e-7):\n",
    "    parameters_values, _ = dictionary_to_vector(parameters)\n",
    "    grad = gradients_to_vector(gradients)\n",
    "    num_parameters = parameters_values.shape[0]\n",
    "    J_plus = np.zeros((num_parameters, 1))\n",
    "    J_minus = np.zeros((num_parameters, 1))\n",
    "    gradapprox = np.zeros((num_parameters, 1))\n",
    "    \n",
    "    for i in range(num_parameters):\n",
    "        \n",
    "        thetaplus = np.copy(parameters_values)                                     \n",
    "        thetaplus[i][0] = thetaplus[i]+ epsilon                              \n",
    "        J_plus[i], _ = forward_propagation_n(X, Y, vector_to_dictionary(thetaplus))\n",
    "        thetaminus = np.copy(parameters_values)                                    \n",
    "        thetaminus[i][0] = thetaminus[i]- epsilon                                   \n",
    "        J_minus[i], _ = forward_propagation_n(X,Y,vector_to_dictionary(thetaminus))                            \n",
    "        \n",
    "        gradapprox[i] = (J_plus[i] - J_minus[i]) / (2 * epsilon)\n",
    "    numerator = np.linalg.norm(gradapprox - grad)                                          \n",
    "    denominator = np.linalg.norm(gradapprox) + np.linalg.norm(grad)                                     \n",
    "    difference = numerator / denominator     \n",
    "    if difference > 2e-7:\n",
    "        print (\"\\033[93m\" + \"There is a mistake in the backward propagation! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    else:\n",
    "        print (\"\\033[92m\" + \"Your backward propagation works perfectly fine! difference = \" + str(difference) + \"\\033[0m\")\n",
    "    \n",
    "    return difference"
   ]
  }
 ],
 "metadata": {
  "coursera": {
   "course_slug": "deep-neural-network",
   "graded_item_id": "n6NBD",
   "launcher_item_id": "yfOsE"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
